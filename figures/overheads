#!/usr/bin/python

import json
import sys
import re
import copy
import os

def displayTag(t):
  return t

def json_careful_loads(s):
  try:
    return json.loads(s)
  except Exception as e:
    sys.stderr.write("[ERR] Error while parsing json: {}\n".format(e))
    sys.exit(1)

def json_careful_readlines(f):
  return [ json_careful_loads(line.rstrip('\n')) for line in f ]

def safeInsert(dict, key, value):
  if key not in dict:
    dict[key] = value
  else:
    sys.stderr.write("[WARN] Key {} is already in use; trying _{} instead.\n".format(key))
    safeInsert(dict, "_" + key, value)

def reCompile(exp):
  return re.compile(exp, re.MULTILINE)

# def parseCommaInteger(s):
#   return int(s.replace(",", ""))

statsPatterns = \
  [ ("time", int, reCompile(r"^wall\s+(\d+)$"))
  , ("space", int, reCompile(r"^\s*Maximum resident set size \(kbytes\): (\d+).*$"))
  # , ("working-set", parseCommaInteger, reCompile(r"^max bytes live: (.*) bytes$"))
  ]

renameConfig = {
  'mlton': 'mlton',
  'mpl': 'mpl',
  'mpl-cc': 'mpl-cc',
  'mlton-working-set': 'mlton-working-set'
}

foundTags = set()
foundProcs = set()

def parseStats(row):
  newRow = copy.deepcopy(row)
  for (name, convert, pat) in statsPatterns:
    m = pat.search(newRow['stdout'] + newRow['stderr'])
    if m:
      safeInsert(newRow, name, convert(m.group(1)))
  newRow['procs'] = int(newRow.get('procs', '1'))
  newRow['config'] = renameConfig[row['config']]

  try:
    newRow['space'] = float(newRow['space'])
  except KeyError:
    pass

  try:
    newRow['time'] = float(newRow['elapsed'])
  except KeyError:
    pass

  foundTags.add(newRow['tag'])
  foundProcs.add(newRow['procs'])

  return newRow

def findTrials(data, config, tag, procs):
  result = []
  for row in data:
    if (row['config'] == config and \
        row['tag'] == tag and \
        row['procs'] == procs):
      result.append(row)
  return result

def averageTime(data, config, tag, procs):
  tms = [ r['time'] for r in findTrials(data, config, tag, procs) if 'time' in r ]

  # cut out the max time to account for possible file IO slowdown
  # (this should only happen the first time the file is loaded)
  if len(tms) > 1:
    maxt = max(tms)
    tms = [ t for t in tms if t != maxt ]

  try:
    return sum(tms) / len(tms)
  except:
    raise ValueError('Error processing average time of config={}, tag={}, procs={}'.format(config, tag, procs))

def averageSpace(data, config, tag, procs):
  sp = [ r['space'] for r in findTrials(data, config, tag, procs) if 'space' in r ]
  try:
    return sum(sp) / len(sp)
  except:
    raise ValueError('Error processing average space of config={}, tag={}, procs={}'.format(config, tag, procs))

# def workingSetSize(data, tag):
#   sp = [ r['working-set'] for r in findTrials(data, "mlton-working-set", tag, 1) if 'working-set' in r ]
#   try:
#     return sp[0] / 1000.0  # working-set is in bytes; divide by 1000 to get KB
#   except:
#     raise ValueError('Error processing working-set size of tag={}'.format(tag))

def tm(t):
  # if t > 10.0:
  #   return int(round(t))
  try:
    if t >= 1.0:
      return round(t, 1)
    elif t >= 0.1:
      return round(t, 2)
    else:
      return round(t, 3)
  except TypeError:
    print ("[ERR] Got type error trying to round {}".format(repr(t)))
    return None

def noLeadZero(t):
  if t < 1:
    return str(t).replace('0', '', 1)
  return str(t)

def sp(kb):
  num = kb
  for unit in ['K','M','G']:
    if num < 1000:
      return "%3.1f %s" % (num, unit)
    num = num / 1000
  return "%3.1f %s" % (num, 'T')

# =========================================================================

def mostRecentResultsFile(ws=False):
  files = os.listdir("../results")
  pattern = r'\d{6}-\d{6}'
  if ws:
    pattern = r'ws-' + pattern
  # A bit of a hack. Filenames are ...YYMMDD-hhmmss, so lexicographic string
  # comparison is correct for finding the most recent (i.e. maximum) file
  mostRecent = max(p for p in files if re.match(pattern, p))
  return mostRecent

if len(sys.argv) > 1:
  timingsFile = sys.argv[1]
else:
  print("[INFO] no results file argument; finding most recent")
  try:
    mostRecent = mostRecentResultsFile()
  except:
    print("[ERR] could not find most recent results file\n " + \
          "  check that these are formatted as 'YYMMSS-hhmmss'")
    sys.exit(1)
  timingsFile = os.path.join('../results', mostRecent)

if len(sys.argv) > 2:
  workingSetFile = sys.argv[2]
else:
  print("[INFO] no working-set file argument; finding most recent")
  try:
    mostRecent = mostRecentResultsFile(ws=True)
  except:
    print("[ERR] could not find most recent results/ws-* file\n " + \
          "  check that these are formatted as 'ws-YYMMSS-hhmmss'")
    sys.exit(1)
  workingSetFile = os.path.join('../results', mostRecent)

print("[INFO] reading {}".format(timingsFile))
with open(timingsFile, 'r') as data:
  resultsData = json_careful_readlines(data)
print("[INFO] reading {}".format(workingSetFile))
with open(workingSetFile, 'r') as data:
  workingSetData = json_careful_readlines(data)
WS = [ parseStats(row) for row in workingSetData ]
D = [ parseStats(row) for row in resultsData ]
P = sorted(list(foundProcs))
maxp = max(foundProcs)

import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.transforms as transforms

# percent difference (b-a)/|a|
def pcd(b, a):
  xx = 100.0 * (b-a) / abs(a)
  return xx

def mplCCOverhead(tag):
  tcc = tm(averageTime(D, 'mpl-cc', tag, 1))
  tb = tm(averageTime(D, 'mlton', tag, 1))
  # return pcd(tcc, tb)
  return tcc / tb

def mplOverhead(tag):
  tcc = tm(averageTime(D, 'mpl', tag, 1))
  tb = tm(averageTime(D, 'mlton', tag, 1))
  # return pcd(tcc, tb)
  return tcc / tb

def interleave(a, b):
  return [ x for t in zip(a, b) for x in t ]

def left(ab):
  return [ ab[2*i] for i in xrange(0, len(ab)/2) ]
def right(ab):
  return [ ab[2*i+1] for i in xrange(0, len(ab)/2) ]

foundTags = list(foundTags)
displayTags = [ "{}({})".format(t, tm(averageTime(D, 'mlton', t, 1))) for t in foundTags ]
N = len(foundTags)
yA = [ mplCCOverhead(tag) for tag in foundTags ]
yB = [ mplOverhead(tag) for tag in foundTags ]
y = interleave(yA, yB)

ytickSpacing = 0.1
yMin = 1.0
yMax = 2.25

yBottom = 1.0
heights = [ h-yBottom for h in y ]
groupWidth = 1.6
barWidth = groupWidth/2

xCenters = [ 2*i for i in xrange(0, N) ]
x = [ xx for i in xCenters for xx in [i-barWidth/2, i+barWidth/2] ]

fig, ax = plt.subplots(1,1)
# fig.subplots_adjust(bottom=0.4)
fig.set_size_inches(12, 5)

ax.set_axisbelow(True)
ax.grid(axis='y')
plt.tick_params(direction='out')
ax.set_ylim([yMin,yMax])
ax.set_xlim([min(x)-1,max(x)+1])
ax.yaxis.set_major_locator(ticker.MultipleLocator(ytickSpacing))
ax.set_xticks(xCenters)
ax.set_xticklabels(displayTags, rotation=65, ha='right', fontsize=12)
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.yaxis.set_ticks_position('left')
ax.xaxis.set_ticks_position('bottom')
plt.bar(left(x), left(heights), align='center', bottom=1, width=barWidth, label='LC+CC')
plt.bar(right(x), right(heights), align='center', bottom=1, color='green', width=barWidth, label='LC only')
ax.legend(loc='upper left')

offset = transforms.ScaledTranslation(10/72., 0, fig.dpi_scale_trans)
for label in ax.xaxis.get_majorticklabels():
  label.set_transform(label.get_transform() + offset)

for i in xrange(0, 2*N, 2):
  if abs(y[i] - y[i+1]) < 0.02:
    yy = max(y[i], y[i+1])
    if yy >= yMax:
      plt.annotate(str("{:.2f}".format(yy)), (xCenters[i/2] + 1.2 * barWidth/2, yMax), ha='right', va='top', fontsize=7)
    else:
      plt.annotate(str("{:.2f}".format(yy)), (xCenters[i/2], yy+0.01), ha='center', fontsize=7)
  else:
    if y[i] >= yMax:
      plt.annotate(str("{:.2f}".format(y[i])), (xCenters[i/2] - 1.2 * barWidth, yMax), ha='right', va='top', fontsize=7)
    else:
      plt.annotate(str("{:.2f}".format(y[i])), (x[i], y[i]+0.01), ha='center', fontsize=7)
    if y[i+1] >= yMax:
      plt.annotate(str("{:.2f}".format(y[i+1])), (xCenters[i/2] + 1.2 * barWidth, yMax), ha='left', va='top', fontsize=7)
    else:
      plt.annotate(str("{:.2f}".format(y[i+1])), (x[i+1], y[i+1]+0.01), ha='center', fontsize=7)


# for i in xrange(0, 2*N):
#   if y[i] >= yMax:
#     if i % 2 == 0:
#       plt.annotate(str(tm(y[i])), (x[i] - 1.2 * barWidth/2, yMax), ha='right', va='top', fontsize=8)
#     else:
#       plt.annotate(str(tm(y[i])), (x[i] + 1.2 * barWidth/2, yMax), ha='left', va='top', fontsize=8)
#   else:
#     plt.annotate(str(tm(y[i])), (x[i], y[i]+0.01), ha='center', fontsize=8)

fig.tight_layout()
plt.savefig('overheads.pdf')

print("[INFO] done reporting {} and {}".format(timingsFile, workingSetFile))
