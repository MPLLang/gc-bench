# gc-bench
Benchmarks for evaluating MPL performance.

## Organization?

Here's how the repo is organized:

  * `bench/` has benchmark codes. Each benchmark has its own subdirectory and
  `.mlb` for compilation.
  * `lib/` is a shared library.
  * `config/` defines how to use different compilers to make a benchmark.
  * `inputs/` contains files which are used as input by some benchmarks.
  * `scripts/` has some utilities for building and running benchmarks.
  * `exp.json` defines the experiments to be performed. It's fairly
  self-explanatory.
  * `exp-cb.json` defines the experiments that can be run on an 8 core machine
     and 12 GB RAM

Individual benchmark binaries are named `BENCH.CONFIG.bin`, where `BENCH` is a
benchmark name (one of the subdirectories of `bench/`) and `CONFIG` is a
compiler configuration (one of the files in `config/`).

The top-level makefile takes a binary name, compiles it and puts the resulting
binary in `bin/`. You can compile a single benchmark with different compilers this way, for example:
```
$ make fib.mpl.bin
$ make fib.mpl-cc.bin
$ make fib.mlton.bin
```
For running them, execute
```
$ bin/fib.mpl.bin @mpl procs 4 -- -N 42
$ bin/fib.mpl-cc.bin @mpl procs 4 -- -N 42
$ bin/fib.mlton.bin -N 42
```


## Benchmark Overview

Here we describe the 15 benchmarks used for comparison with MLton and MPL.

### Centrality
This computes single-source betweenness centrality,
based on the Ligra implementation.
The input is a randomly
generated power-law graph with approximately
16.7M vertices and
199M edges, symmetrized.
(A symmetrized graph is an undirected graph where each edge is
represented as two directed edges.)

### Dedup
computes the set of unique words of an input text by first separating the
text into words, and then deduplicating the words by hashing.
The input text is approximately 60MB with 6.3M words and
99K unique words.

### Dense-Matrix Multiplication (dmm)
multiplies two $1024 \times 1024$
dense matrices of 64-bit floating-point elements
using the simple $O(n^3)$-work algorithm.

### Grep
is an implementation of the Unix ``grep'' utility.
The input text is 60MB with 6.3M lines, and the search pattern appears on
138K lines.

### Mergesort (msort)
sorts 10M 64-bit integers.
The input is uniformly random, generated by a hash function.

### Nearest-Neighbors (nn)
computes all nearest neighbors within a set of 2D points (i.e. for each point,
the nearest other point within the set) by constructing an intermediate
quad-tree and then querying it in parallel.
The input is 1M points distributed uniformly randomly within a square.

### Palindrome
finds the longest (contiguous) substring which is a palindrome using a
polynomial rolling hash.
The input is 1M characters.

### Primes
generates all prime numbers that are less than 100M (approximately 5.8M primes)
with a parallel sieve.

### Quickhull
computes the convex hull of 10M uniformly random points distributed within a
circle.

### Random
generates 1B pseudo-random 64-bit numbers with a hash function.

### Raytracer (ray)
computes an image of $1000 \times 1000$ pixels by ray-tracing.

### Reverb
applies an artificial reverberation effect to an audio file.
The input is approximately 4 minutes long with a
sample rate of 44.1 kHz at 16 bits per sample.

### Seam-carve
is a parallel implementation of the seam-carving technique for
content-aware rescaling.
This benchmark removes 100 vertical seams from a panoramic image of approximately 1.5M
pixels.

### Suffix-array
computes the suffix array of a uniformly random input text of 10M characters.

### Tokens
separates a text into tokens, using whitespace as delimiters.
The input text is approximately 60MB with 6.3M tokens.

## Run

Run all experiments for cores ranging from 1 to 70 with 10 core increments.
By default, each benchmark is run once (with warmup).
You can pass `--repeat N` to do `N` repetitions of each benchmark.
```
$ ./run
```
```
$ ./run --repeat 10
```
Similar to the `run` script, there is a `run-cb` 
script which only runs  the less memory hungry benchmarks on cores ranging from 1 to 7.

Both the scripts produce a file `results/XXX` where `XXX` is the
current date/time. The `report` script will print a summary of the results. 
With no arguments, this selects the most recent results. Or, you can pick a
particular file.

```
$ ./report
```
```
$ ./report results/XXX
```
